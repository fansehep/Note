### Greenplum 用于事务和分析工作负载的混合数据库

1. 介绍

   - Greenplum 的大规模并行处理 (MPP) 架构将**数据**分成互不相连的部分，存储在各个工人段之间。

   - Greenplum 的用户通过协调节点之间与系统进行交互，底层的分布式架构对用户是透明的。对于给定的查询，协调器会对其进行优化，进行并行处理。并将生成的计划分派给分段。每个段并行执行该计划，并在需要时在段之间打乱元组。这种方法大大提高了长时间运行的分析查询的速度。

     - 协调器收集结果，然后传递给客户端。

   - OLTP 联机事务处理 OLAP 联机分析处理

   - OLTP 主要用来记录某类业务事件的发生，如购买行为，当行为产生后，系统会记录是谁在何时何地做了何事，

   - 当数据积累到一定程度，我们需要对过去发生的事情做一个总结分析时，就需要把过去一段时间内产生的数据拿出来进行统计分析，从中获取我们想要的信息，为公司做决策提供支持，这时候就需要 OLTP 了.

   - 因为OLTP所产生的业务数据分散到不同的业务系统中, 而 OLAP 往往需要将不同的业务数据集中到一起进行统一综合的分析. 这时候就需要更具业务分析需求做对应的数据清洗后存储在数据仓库中，然后由数据仓库来统一提供 OLAP 分析。

   - |              |       OLTP  System       | OLAP System        |
     | ------------ | :----------------------: | ------------------ |
     | 业务目的     | 处理业务，如订单，合同等 | 业务支持决策       |
     | 面向对象     |       业务处理人员       | 分析决策人员       |
     | 主要工作负载 |        增，删，改        | 查询               |
     | 主要衡量指标 |        事务吞吐量        | 查询响应速度 (QPS) |

     OLAP 所需要分析的数据都是由 OLTP 所产生的，OLAP 是 OLTP 的一个扩展.

     一个让 OLTP 产生的数据发现的价值的过程.

     同时 OLAP 还分为 ROLAP , MOLAP

     ROLAP

     - 关系型联机分析处理
     - ROLAP  为代表的有传统关系型数据库，MPP 分布式数据库以及基于 Hadoop 的Spark / Impala，特点是能同时链接明细数据和汇总数据，实时更具用户提出的需求对数据进行计算后返回给用户，所以用户使用相对比较灵活，可以随意选择维度组合来进行实时计算.
       - 由于采用了实时计算技术，所以 ROLAP 的缺点也比较明显，当计算的数据量达到一定级别或并发数达到一定级别的时候，一定会出现性能问题。
     - MPP 分布式数据库则解决了一些问题.

     MOLAP

     - 多维联机分析处理

   - 1) 使用 ACID 保证改进数据加载到并行系统中
     2) 减少 OLTP 工作负载中普遍存在的服务点查询的响应时间.
     3) 资源组，它能够在不同类型的工作负载或用户组之间隔离资源.

     Greenplum 设计时将 OLAP 查询作为第一类公民，而 OLTP 工作负载并不是主要工作的焦点。两阶段提交对只更新少数元组的事务造成性能损失。

     Greenplum 扩充为 HTAP 系统的关键工作

     - OLAP 数据库 => HTAP 数据库系统的挑战
     - 一个全局死锁检测器，以减少锁开销，增加 OLTP 响应时间，同时不牺牲 OLAP 工作负载的性能
     - 切换到单阶段提交协议，加快保证只更新驻留在一个精确段上的数据的事务。
     - 开发了一个新的资源隔离组件来管理 OLTP 和 OLAP 工作负载，这可以避免高并发场景中的资源冲突.

2. 相关工作

   - 混合交易和分析处理 (HTAP) 系统，与OLAP  或 OLTP 系统相比，HTAP 系统带来了一些好处。
     - HTAP 可以减少新的数据分析任务的等待时间. 因为没有 ETL  传输延迟，它使得3实时数据分析不需要额外的组件或外部系统就可以实现。其次，HTAP 系统可以在硬件和管理方面降低整体业务成本。

3. Greenplum 的 MPP 架构

   - 如果想要同时支持 pb级数据和高性能分析
     - 数据可扩展性: 数据总量太大，无法存储在单个主机上.
     - 计算可扩展性: 处理并发的能力受限于单个主机的计算资源.
     - 高可用性: 如果单个主机不可用，那么整个数据库系统也不可用

   3.1 段数据库的角色和责任

   - 一个 Greenplum 集群由许多主机的许多段所组成。在整个数据库系统中只有一个称为协调器段数据库的段数据库. 其他的都被简称为段. 协调段直接连接到用户客户端，协调器从他们那里接收命令或查询，生成一个分布式查询计划，再根据计划生成分布式进程。收集结果，最后返回给客户端. 段作为用户数据的主要存储，并从协调器执行分布式计划的特定部分。为了实现高可用性，一些段被配置为镜像(或协调器的备用)。镜像(和备用) 不会直接参与计算。相反，他们会连续地从相应的主段接受 WAL 日志, 并动态地回放日志.

     Greenplum 遵循的是无共享架构. 协调器和段有自己的共享内存和数据目录。Coordinator 只通过网络与网段通信.

   3.2 分布式方案 与 分布式执行者

   - 通常，对于分布式关系，每个段只存储整个数据的一小部分。当连接两个关系时，我们经常需要检查来自不同段的两个元组是否匹配连接条件。这意味着 Greenplum 必须在段之间移动数据. 以确保所有可能匹配的元组都在同一个段中。Greenplum 引入了一个名为 Motion 的新计划节点来实现这样的数据移动.
   - Motion 计划节点使用网络来发送和接受来自不同的分段(主机) 的数据，运动计划节点会自然地将计划切割成碎片，Motion 下方或上方的每一块在 Greenplum 中被称为一片。每个切片由一组分布式进程执行。这组进程称为 gang.
   - 有了上面提到的提议的Motion plan 节点和gang. Greenplum 的查询计划和执行器都变成了分布式的。计划将分配到每个进程，并根据

   3.3 分布式事务管理

   - 在 Greenplum 集群中，每个段运行了一个增强的 PostgreSQL 实例, 每个段中的事务同步提交或终止. 为了确保 ACID 属性，Greenplum 使用了分布式快照和一个二阶段提交协议。分布式事务管理的性能对于将 Greenplum 增强为一个 HTAP 系统非常重要.

   3.4 混合存储和优化器

   - Greenplum 支持 PostgreSQL 原生堆表. 这是一个面向行的存储, 拥有固定的大小的块和一个运行在段上的查询进程共享的缓冲区缓存，方便并发读写操作。在 Greenplum 中引入了两种新的表类型, 附加优化的面向行存储和附加优化的面向列存储. 与随机访问相比

4. 对象锁优化

   - OLTP 性能的基石 对象锁优化,
     - 核心思想是通过检测器算法解决分布式环境下的全局死锁问题.
   - Greenplum 中的锁
     - 锁被广泛应用于数据库，以防止不同粒度级别的竞争条件.
     - 针对不同的用例设计了三种不同的锁
       - 自旋锁
       - LW_lock
       - 对象锁
     - 自选锁和 LW_lock 用于读写共享内存时保护临界区域，通过遵循一些规则(例如以相同的方式获取锁), 我们可以摆脱涉及这两种锁的死锁
     - AccessShareLock
     - RowShareLock
     - RowExecusiveLock
     - ShareUpdateExcluesiveLock
     - ShareLock
     - ShareRowExclusiveLock
     - ExclusiveLock
     - AccessExclusiveLock
   - 一些对象，如关系，可以由事务并发操作。当访问这样的对象时，锁应该以正确的模式持有，以保护对象，Greenplum 采用两阶段锁,
     - 在第一阶段持有锁，在事务提交或中止时释放锁。从 PostgreSQL 继承而来, Greenplum 中有 8 种不同级别的锁模式。更高级别的锁模式可以实现更严格的并发控制粒度. 所有的锁模式， 他们的冲突模式以及对应的典型语句如表 1 所示, 作为一个基于 MPP 的数据库，锁的逻辑与算法与 PostgreSQL 是不同的。PostgreSQL 的锁逻辑不会检测或解决在 Greenplum 这样的 MPP 数据库中经常遇到的全局死锁用例. 

   4.2 全局死锁问题

   - 在 Greenplum 这样的分布式系统中, INSERT  DELETE 和  UPDATE DML 语句的锁级别在处理全局死锁时非常重要，这些 DML 语句的锁定行为如下 :
     - 在解析 - 分析阶段，事务以某种模式锁定目标关系
     - 在执行过程中，事务将其标识符写入元组。这只是使用事务锁锁定元组的一种方式.
   - 在单段数据库中，比如 PostgreSQL, 第一阶段通常会以 RowExclusive 模式锁定目标关系，这样他们就可以并发运行。只有当两个事务碰巧写入 (UPDATE 或者 DELETE) 同一个元组时，一个事务才会等待该元组的事务锁，直到另一个事务被提交或终止。锁的依赖关系存储在每个段实例的共享内存中。如果发生死锁，很容易扫描到共享内存中的锁信息来打破他.
   - 这种方法在 Greenplum 的分布式架构中是不够的。即使 Greenplum 集群中的每个段都是一个增强的 PostgreSQL 实例, 带有本地死锁处理程序, 但如果等待行为发生在不同的段上，也无法避免全局死锁.

   4.3 全局死锁检测算法

   - 为了解决全局死锁问题，在Greenplum 6 中提出了一种检测机制.
     - Greenplum 在协调段上启动一个守护进程
     - 守护进程定期收集每个段上的等待图
     - 守护进程检查是否发生了全局死锁
     - 守护进程使用了预定义的策略来打破全局死锁，比如终止最小的事务.
   - GDD 守护进程收集每个段的本地等待图(包括协调器的)，并构建一个全局等待图。它是一组本地等待的有向图，其中每个顶点代表一个事务，边缘从等待事务开始到持有事务。对于每一个代表一笔交易的顶点，其出边的数量就是该顶点的出度，其入边的数量就是该顶点的入度。一个顶点的局部度是仅在单个线段的等待图中计算的值。

5. 分布式事务管理

   - Greenplum 中的事务是在协调器上创建的，并分发给参与段。协调器为每个事务分配分布式事务标识符(一个单调递增的整数), 段为从协调器接受到的每个分布式事务分配本地事务标识符。段使用本地 PostgreSQL 事务机制来生成本地事务标识符. 分布式事务标识符在全局级别唯一标识一个事务。本地事务标识符可以在一个段内唯一地标识一个事务。段还可以使用本地 PostgreSQL 机制生成本地快照。协调器被委派了全局级别的指责 -- 创建分布式事务，分布式快照，并在参与的段之间协调两阶段提交协议。分布式快照由一个正在进行的分布式事务标识符列表(和快照创建时)提交的最大的分布式事务标识符组成。这种设置使 Greenplum 能够以隔离而一致的方式执行分布式事务。

   5.1 分布式事务隔离

   - PostgreSQL 使用多版本并发控制(MVCC), 通过创建元组的多个版本，而不是原地更新它。让并发事务继续进行而不阻塞。每个版本都印有创建事务的标识符
   - Greenplum 扩展了这一概念，通过添加分布式快照来在分布式设置中实现事务隔离。元组可见性是通过结合本地和分布式快照信息来确定的。接下来，让我们考虑在段中对元组进行 DML 操作. 在一个给定的事务中，当我们修改一个元组时，我们创建的这个元组的新副本。并使用本地事务标识符标记它。对于每个元组，我们还维护本地事务标识符与其对应的分布式事务标识符之间的映射，该分布式事务标识符是最后创建或者修改她的。在扫描操作期间。我们从这个映射中提取一个元组的分布式事务标识符。将这个分布式事务标识符与分布式快照(由协调器提供)结合使用，扫描操作符确定了元组的可见性。

   5.2 单阶段提交协议

   - 协调器使用两阶段提交来确保一个事务在所有段上要么被提交要么被中之。协调器创建一个后端进程来处理客户端连接。后端进程在受到客户端提交请求后，在参与的段之间启动两阶段提交协议。

6. 资源隔离

   - 如何在高并发，混合的工作负载环境中缓解资源竞争造成的性能下降是一个具有挑战性的问题。
   - 分析工作负载在并发运行时，对事务性工作负载有很大影响。通常情况下，分析工作负载会消耗大量的 cpu 内存 和 IO 带宽. 这会抢占事务性的工作负载的资源，导致事务性查询延迟。为了减少干扰，Greenplum 引入了 Resource Group 来隔离不同类型的工作负载或用户组之间的资源。目前，资源组支持对不同技术的计算资源和内存资源进行隔离。
   - CPU 隔离基于控制组技术实现。Cgroup 是一种 Linux 内核特性, 可以限制和隔离一组进程的资源使用。从 Cgroup 树状结构角度来看，一个资源组被实现为一个内存节点，属于这个资源组的所有进程都是它的子进程。为了对CPU 使用情况进行优先排序，可以为每个资源组设置两种配置，并为该组中的所有进程设置两种配置。一种是 CPU， CPU 使用率 或 优先级。另一个是 CPUtest. CPU, 它指定了这个资源组可以使用的CPU内核。前一种是软控制 : 如果没有并发工作负载，资源组中的某个进程可以使用比制定限制更多的 CPU 资源。后一种是硬控制，限制一个进程在一个资源组中最多可以使用的 CPU 核数.
   - 在 Greenplum 中，内存隔离是基于内存管理模块 Vmemtracker 负责跟踪 Greenplum 数据库内核中的所有内存使用情况. Greenplum 利用该特性来控制不同资源组之间的内存使用情况。与 CPU 不同的是，内存是一种硬资源，一旦分配，就不能立即回收。当某个资源组的内存使用超过其限制时，该资源组中的查询将被取消，但在现实工作负载中，显示控制内存使用量并不容易，例如，很难得到一个哈希表的显式内存使用量。为了使内存资源的执行更加健壮，资源组引入了三层来管理内存的使用情况。
     - 第一层强制在插槽内存上，他控制组中单个查询的内存使用情况.
     - 第二层强制在一组共享内存上，当同一资源组中的查询过度使用插槽内存时，可以使用该层。组共享内存可以通过每个资源组 的 MEMORY_SHARED_QUOTA 参数来设置, 最后一层是全局共享内存，他是不同组之间内存使用的最后一个捍卫者。直到三层都不能约束数据库中当前正在运行的查询的内存使用情况，查询取消机制才会被触发.
   - 